{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Convert a video to a podcast (2 people - video format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sieve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1. Download a YouTube video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.youtube.com/watch?v=AKJfakEsgy0\"\n",
    "resolution = \"highest-available\"\n",
    "include_audio = True\n",
    "\n",
    "youtube_to_mp4 = sieve.function.get(\"sieve/youtube_to_mp4\")\n",
    "output_video = youtube_to_mp4.run(url, resolution, include_audio)\n",
    "\n",
    "print(output_video.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2. Summarize it into a conversational style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "backend = \"gemini-1.5-flash\" #for more complex tasks use \"gemini-1.5-pro\"\n",
    "prompt = \"Summarize the video into a conversation between two people.\"\n",
    "fps = 30\n",
    "audio_context = True\n",
    "\n",
    "visual_qa = sieve.function.get(\"sieve/visual-qa\")\n",
    "output = visual_qa.run(output_video, backend, prompt, fps, audio_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3. Process summary text (summary as conversation between 2 people)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the text by newline character\n",
    "conversation_list = output.split('\\n')\n",
    "# Remove empty strings from the list\n",
    "conversation_list = [line for line in conversation_list if line.strip()]\n",
    "\n",
    "# Get a list of dialogues with each item as a tuple of format (speaker_id,text).\n",
    "summary_conversation_list = []\n",
    "\n",
    "for line in conversation_list:\n",
    "    if line.startswith(\"Person 1:\"):\n",
    "        speaker = \"Person 1\"\n",
    "        text = line.replace(\"Person 1:\", \"\").strip()\n",
    "    elif line.startswith(\"Person 2:\"):\n",
    "        speaker = \"Person 2\"\n",
    "        text = line.replace(\"Person 2:\", \"\").strip()\n",
    "    else:\n",
    "        # Find the position of the first colon\n",
    "        colon_index = line.find(\":\")\n",
    "        # If a colon is found, return the content after it\n",
    "        if colon_index != -1:\n",
    "            text = line[colon_index + 1:].strip()\n",
    "            speaker = line[:colon_index]\n",
    "        else: # If no colon is found, return the entire sentence\n",
    "            speaker = \"Unknown\"\n",
    "            text = line.strip()\n",
    "    \n",
    "    summary_conversation_list.append((speaker, text))\n",
    "\n",
    "# Display the processed conversation\n",
    "for speaker, text in summary_conversation_list:\n",
    "    print(f\"{speaker}: {text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Person 1: Did you know that giant clams are more efficient at converting energy from the sun than solar panels or even leaves? <br><br>\n",
    "Person 2: That's really interesting! What's their secret? <br><br>\n",
    "Person 1: They have algae living inside them. The algae takes light from the sun and converts it to energy for itself and the clam. <br><br>\n",
    "Person 2: Wow! So we could learn from them to make better solar energy?<br><br>\n",
    "Person 1: That's right. People are trying to extract energy from algae, but our current process is only 10% efficient. These clams are 67% efficient.<br><br>\n",
    "Person 2: How do they do it?<br><br>\n",
    "Person 1: It's because of these shimmery cells on the clam. They reflect sunlight down onto the algae inside the clam, evenly coating them with the perfect dose of light.<br><br>\n",
    "Person 2: Fascinating! There's so much to learn from nature. <br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4. Convert each conversation turn text to speech & generate its talking avatar\n",
    "\n",
    "feed each turn of output (processed_conversation) to *sieve/tts* with either speaker1 or speaker2 voice iteratively â†’ generate audio1, audio2, audio3, .., (Odd number files belong to speaker1 and even numbered files belong to speaker2).\n",
    "During each turn, generates its talking avatar. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def reencode_video(input_path, output_path):\n",
    "    \"\"\"\n",
    "    Re-encode a video to normalize codec properties.\n",
    "    \"\"\"\n",
    "    command = [\n",
    "        \"ffmpeg\",\n",
    "        \"-loglevel\", \"warning\",\n",
    "        \"-i\", input_path,\n",
    "        \"-r\", \"30\",\n",
    "        \"-c:v\", \"libx264\",\n",
    "        \"-preset\", \"fast\",\n",
    "        \"-crf\", \"23\",\n",
    "        \"-c:a\", \"aac\",\n",
    "        output_path\n",
    "    ]\n",
    "\n",
    "    # Execute the command using subprocess.run\n",
    "    try:\n",
    "        result = subprocess.run(command, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "        print(f\"Re-encoded: {input_path} -> {output_path}\")\n",
    "        print(result.stdout)  # Optionally print the standard output\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"Error occurred while merging videos.\")\n",
    "        print(e.stderr)  # Optionally print the error message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4. Convert each conversation-turn's text to speech & generate its talking avatar.\n",
    "tts = sieve.function.get(\"sieve/tts\")\n",
    "portrait_avatar = sieve.function.get(\"sieve/portrait-avatar\")\n",
    "\n",
    "# tts inputs:\n",
    "print(\"generating tts audio and its avatar video...\")\n",
    "odd_voice = \"cartesia-commercial-man\"\n",
    "even_voice = \"cartesia-sweet-lady\"\n",
    "reference_audio = sieve.File(url=\"\") #not passing this argument results throws error.\n",
    "\n",
    "# portrait-avatar inputs\n",
    "odd_image = sieve.File(\"https://storage.googleapis.com/sieve-prod-us-central1-public-file-upload-bucket/c4d968f5-f25a-412b-9102-5b6ab6dafcb4/4c35f0b2-5925-4acc-8870-0b06641fd5f6-boy.jpg\")\n",
    "even_image = sieve.File(url=\"https://storage.googleapis.com/sieve-prod-us-central1-public-file-upload-bucket/dea37047-9b88-44b7-aacb-a5f4745f1f2d/db7a439e-24f8-40cd-b29d-43935e1a2ae7-input-source_image.jpg\")\n",
    "aspect_ratio = \"16:9\"\n",
    "\n",
    "turn = 0\n",
    "normalized_videos = []\n",
    "for speaker, text in summary_conversation_list:\n",
    "    turn += 1\n",
    "    if turn % 2 != 0: # odd-turn of conversation\n",
    "        target_audio = tts.run(odd_voice, text,reference_audio,\"curiosity\")\n",
    "        avatar_video = portrait_avatar.run(source_image=odd_image, driving_audio=target_audio,aspect_ratio = aspect_ratio)\n",
    "        print(f'odd turn: done tts and avatar generation for turn-{turn}')\n",
    "    else: #even-turn\n",
    "        target_audio = tts.run(even_voice, text, reference_audio,\"curiosity\")\n",
    "        avatar_video = portrait_avatar.run(source_image=even_image, driving_audio=target_audio,aspect_ratio = aspect_ratio)\n",
    "        print(f'even turn: done tts and avatar generation for turn-{turn}')\n",
    "    #Encode generated video to ensure same frame rate, video codec, audio codec and similar video quality.\n",
    "    normalized_video = f\"normalized_{turn}.mp4\"\n",
    "    reencode_video(avatar_video.path, normalized_video)\n",
    "    normalized_videos.append(normalized_video)\n",
    "print(\"done generating video avatars for all individual conversation turns!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5. Merge video files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_videos(video_list_file):\n",
    "    \"\"\"\n",
    "    Merge videos listed in the video_list_file into a single video.\n",
    "    \"\"\"\n",
    "    # Step 1: Read the video list from the file\n",
    "    with open(video_list_file, 'r') as f:\n",
    "        video_files = f.readlines()\n",
    "\n",
    "    # Step 2: Normalize (re-encode) each video in the list\n",
    "    normalized_videos = []\n",
    "    for i, video in enumerate(video_files):\n",
    "        video = video.strip()  # Remove any extra spaces or newline characters\n",
    "        normalized_video = f\"normalized_{i+1}.mp4\"\n",
    "        reencode_video(video, normalized_video)\n",
    "        normalized_videos.append(normalized_video)\n",
    "        if i == 3:\n",
    "            break\n",
    "    \n",
    "    # Step 3: Write the normalized video list to a new text file for concatenation\n",
    "    with open('normalized_videos.txt', 'w') as f:\n",
    "        for normalized_video in normalized_videos:\n",
    "            f.write(f\"file '{normalized_video}'\\n\")\n",
    "            \n",
    "    # # Step 4: Concatenate the normalized videos\n",
    "    output_path = \"merged_output_video.mp4\"\n",
    "    command = [\n",
    "        \"ffmpeg\",\n",
    "        \"-f\", \"concat\",\n",
    "        \"-safe\", \"0\",\n",
    "        \"-i\", \"normalized_videos.txt\",\n",
    "        \"-loglevel\", \"warning\",\n",
    "        \"-c\", \"copy\",\n",
    "        output_path     \n",
    "    ]\n",
    "    \n",
    "    # subprocess.run(command)\n",
    "    # Execute the command using subprocess.run\n",
    "    try:\n",
    "        result = subprocess.run(command, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "        print(\"Merge successful!\")\n",
    "        print(result.stdout)  # Optionally print the standard output\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"Error occurred while merging videos.\")\n",
    "        print(e.stderr)  # Optionally print the error message\n",
    "    return output_path\n",
    "\n",
    "# Example usage\n",
    "final_output = merge_videos('videos.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sieve",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
