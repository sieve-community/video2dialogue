{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Convert a video to a podcast (2 people - video format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sieve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1. Download a YouTube video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = \"https://www.youtube.com/watch?v=AKJfakEsgy0\"\n",
    "url = \"https://youtube.com/shorts/D-F32ieZ4WA?si=X7QzBXMEuJM6d-E4\"\n",
    "\n",
    "resolution = \"highest-available\"\n",
    "include_audio = True\n",
    "\n",
    "youtube_to_mp4 = sieve.function.get(\"sieve/youtube_to_mp4\")\n",
    "output_video = youtube_to_mp4.run(url, resolution, include_audio)\n",
    "\n",
    "print(output_video.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2. Summarize it into a conversational style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_summarizer = sieve.function.get(\"sieve/visual-qa\")\n",
    "function_json = {\n",
    "  \"type\": \"list\",\n",
    "  \"items\": {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "      \"speaker_name\": {\n",
    "        \"type\": \"string\",\n",
    "        \"description\": \"The speaker name\"\n",
    "      },\n",
    "      \"dialogue\": {\n",
    "        \"type\": \"string\",\n",
    "        \"description\": \"dialogue\"\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "backend = \"gemini-1.5-flash\" \n",
    "prompt = \"Summarize the video into a conversation between two people. Denote first speaker as 'Person 1' and second speaker as 'Person 2'.\"\n",
    "summary_as_conversation = visual_summarizer.run(output_video, backend, prompt, fps=1, audio_context= True,function_json=function_json)\n",
    "print(\"Summary: \\n\", summary_as_conversation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3. Convert each conversation turn text to speech & generate its talking avatar\n",
    "\n",
    "feed each turn of output (processed_conversation) to *sieve/tts* with either speaker1 or speaker2 voice iteratively â†’ generate audio1, audio2, audio3, .., (Odd number files belong to speaker1 and even numbered files belong to speaker2).\n",
    "During each turn, generates its talking avatar. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def reencode_video(input_path, output_path):\n",
    "    \"\"\"\n",
    "    Re-encode a video to normalize codec properties.\n",
    "    \"\"\"\n",
    "    command = [\n",
    "        \"ffmpeg\",\n",
    "        \"-loglevel\", \"warning\",\n",
    "        \"-i\", input_path,\n",
    "        \"-r\", \"30\",\n",
    "        \"-c:v\", \"libx264\",\n",
    "        \"-preset\", \"fast\",\n",
    "        \"-crf\", \"23\",\n",
    "        \"-c:a\", \"aac\",\n",
    "        output_path\n",
    "    ]\n",
    "\n",
    "    # Execute the command using subprocess.run\n",
    "    try:\n",
    "        result = subprocess.run(command, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "        print(f\"Re-encoded: {input_path} -> {output_path}\")\n",
    "        print(result.stdout)  # Optionally print the standard output\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"Error occurred while merging videos.\")\n",
    "        print(e.stderr)  # Optionally print the error message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3. Convert each conversation-turn's text to speech & generate its talking avatar.\n",
    "tts = sieve.function.get(\"sieve/tts\")\n",
    "portrait_avatar = sieve.function.get(\"sieve/portrait-avatar\")\n",
    "\n",
    "# tts inputs:\n",
    "print(\"generating tts audio and its avatar video...\")\n",
    "odd_voice = \"cartesia-commercial-man\"\n",
    "even_voice = \"cartesia-sweet-lady\"\n",
    "reference_audio = sieve.File(url=\"\") #not passing this argument results throws error.\n",
    "\n",
    "# portrait-avatar inputs\n",
    "odd_image = sieve.File(\"https://storage.googleapis.com/sieve-prod-us-central1-public-file-upload-bucket/c4d968f5-f25a-412b-9102-5b6ab6dafcb4/4c35f0b2-5925-4acc-8870-0b06641fd5f6-boy.jpg\")\n",
    "even_image = sieve.File(url=\"https://storage.googleapis.com/sieve-prod-us-central1-public-file-upload-bucket/dea37047-9b88-44b7-aacb-a5f4745f1f2d/db7a439e-24f8-40cd-b29d-43935e1a2ae7-input-source_image.jpg\")\n",
    "aspect_ratio = \"1:1\"\n",
    "\n",
    "turn = 0\n",
    "normalized_videos = []\n",
    "for entry in summary_as_conversation:\n",
    "    turn += 1\n",
    "    if turn % 2 != 0: # odd-turn of conversation\n",
    "        target_audio = tts.run(odd_voice, entry['dialogue'],reference_audio,\"curiosity\")\n",
    "        avatar_video = portrait_avatar.run(source_image=odd_image, driving_audio=target_audio,aspect_ratio = aspect_ratio)\n",
    "        print(f'odd turn: done tts and avatar generation for turn-{turn}')\n",
    "    else: #even-turn\n",
    "        target_audio = tts.run(even_voice, entry['dialogue'], reference_audio,\"curiosity\")\n",
    "        avatar_video = portrait_avatar.run(source_image=even_image, driving_audio=target_audio,aspect_ratio = aspect_ratio)\n",
    "        print(f'even turn: done tts and avatar generation for turn-{turn}')\n",
    "    #Encode generated video to ensure same frame rate, video codec, audio codec and similar video quality.\n",
    "    normalized_video = f\"normalized_{turn}.mp4\"\n",
    "    reencode_video(avatar_video.path, normalized_video)\n",
    "    normalized_videos.append(normalized_video)\n",
    "print(\"done generating video avatars for all individual conversation turns!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4. Merge video files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_videos(video_list_file):\n",
    "    \"\"\"\n",
    "    Merge videos listed in the video_list_file into a single video.\n",
    "    \"\"\"\n",
    "    # Step 1: Read the video list from the file\n",
    "    with open(video_list_file, 'r') as f:\n",
    "        video_files = f.readlines()\n",
    "\n",
    "    # Step 2: Normalize (re-encode) each video in the list\n",
    "    normalized_videos = []\n",
    "    for i, video in enumerate(video_files):\n",
    "        video = video.strip()  # Remove any extra spaces or newline characters\n",
    "        normalized_video = f\"normalized_{i+1}.mp4\"\n",
    "        reencode_video(video, normalized_video)\n",
    "        normalized_videos.append(normalized_video)\n",
    "        if i == 3:\n",
    "            break\n",
    "    \n",
    "    # Step 3: Write the normalized video list to a new text file for concatenation\n",
    "    with open('normalized_videos.txt', 'w') as f:\n",
    "        for normalized_video in normalized_videos:\n",
    "            f.write(f\"file '{normalized_video}'\\n\")\n",
    "            \n",
    "    # # Step 4: Concatenate the normalized videos\n",
    "    output_path = \"merged_output_video.mp4\"\n",
    "    command = [\n",
    "        \"ffmpeg\",\n",
    "        \"-f\", \"concat\",\n",
    "        \"-safe\", \"0\",\n",
    "        \"-i\", \"normalized_videos.txt\",\n",
    "        \"-loglevel\", \"warning\",\n",
    "        \"-c\", \"copy\",\n",
    "        output_path     \n",
    "    ]\n",
    "    \n",
    "    # subprocess.run(command)\n",
    "    # Execute the command using subprocess.run\n",
    "    try:\n",
    "        result = subprocess.run(command, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "        print(\"Merge successful!\")\n",
    "        print(result.stdout)  # Optionally print the standard output\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"Error occurred while merging videos.\")\n",
    "        print(e.stderr)  # Optionally print the error message\n",
    "    return output_path\n",
    "\n",
    "# Example usage\n",
    "final_output = merge_videos('videos.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Advanced] Parallelized Code Using concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# Step 4. Convert each conversation-turn's text to speech & generate its talking avatar.\n",
    "# tts inputs:\n",
    "print(\"generating tts audio and its avatar video...\")\n",
    "reference_audio = sieve.File(url=\"\")  # Required argument to avoid errors\n",
    "\n",
    "turn = 0\n",
    "normalized_videos = []\n",
    "turn_results = {}  # Dictionary to store normalized videos by turn\n",
    "\n",
    "# ThreadPoolExecutor for concurrent execution\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    # List to keep track of all submitted jobs\n",
    "    future_to_turn = {}\n",
    "\n",
    "    # Submit TTS and avatar generation jobs\n",
    "    for entry in summary_as_conversation:\n",
    "        turn += 1\n",
    "        if turn % 2 != 0:  # Odd-turn of conversation\n",
    "            target_audio_future = tts.push(voice1, entry['dialogue'], reference_audio, \"curiosity\")\n",
    "            avatar_video_future = portrait_avatar.push(\n",
    "                source_image=image1, \n",
    "                driving_audio=target_audio_future.result(), \n",
    "                aspect_ratio=\"1:1\"\n",
    "            )\n",
    "        else:  # Even-turn\n",
    "            target_audio_future = tts.push(voice2, entry['dialogue'], reference_audio, \"curiosity\")\n",
    "            avatar_video_future = portrait_avatar.push(\n",
    "                source_image=image2, \n",
    "                driving_audio=target_audio_future.result(), \n",
    "                aspect_ratio=\"1:1\"\n",
    "            )\n",
    "\n",
    "        # Store the avatar video future and turn in a dictionary for tracking\n",
    "        future_to_turn[avatar_video_future] = turn\n",
    "\n",
    "    # Process avatar generation results as they complete\n",
    "    for future in as_completed(future_to_turn):\n",
    "        turn = future_to_turn[future]\n",
    "        try:\n",
    "            avatar_video = future.result()  # Wait for the avatar video to complete\n",
    "            print(f\"Done TTS and avatar generation for turn-{turn}\")\n",
    "            \n",
    "            # Re-encode the video\n",
    "            normalized_video = f\"normalized_{turn}.mp4\"\n",
    "            reencode_video(avatar_video.path, normalized_video)\n",
    "\n",
    "            # Store normalized video path in a dictionary\n",
    "            turn_results[turn] = normalized_video\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing turn-{turn}: {e}\")\n",
    "\n",
    "# Append normalized videos to the list in the sequential order of turns\n",
    "for turn in sorted(turn_results.keys()):\n",
    "    normalized_videos.append(turn_results[turn])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Advantages of This Approach**\n",
    "- Concurrency: Multiple TTS and avatar generation tasks are submitted and executed in parallel, reducing the overall processing time.<br>\n",
    "- Asynchronous Result Handling: *as_completed* ensures that completed tasks are processed immediately, improving efficiency. <br>\n",
    "- Scalability: Can handle a larger number of turns or tasks without significant changes to the code.\n",
    "<br><br>\n",
    "NB:\n",
    "- Correct Ordering:Ensures that the normalized_videos list is populated in the correct order of turns, regardless of the order in which tasks complete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
